{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 目标:将故障日志中意义相近的故障现象描述进行聚类"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1:将日志中的故障描述提取到List中,并进行分词处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import jieba\n",
    "import xlrd\n",
    "\n",
    "fileSegWordDonePath ='corpusSegDone.txt'\n",
    "\n",
    "data = xlrd.open_workbook('log_infos.xls')  # 打开xls文件\n",
    "table1 = data.sheets()[0] # 打开第一张表\n",
    "\n",
    "num_cols = table1.col_values(8)\n",
    "\n",
    "err_info = []\n",
    "\n",
    "errs = num_cols[1:]\n",
    "\n",
    "for curr_index in range(len(errs)):\n",
    "    curr_err = errs[curr_index].encode(\"utf-8\")\n",
    "    if curr_err != '' and curr_err != '故障描述' :\n",
    "        err_info.append(curr_err)\n",
    "\n",
    "\n",
    "fileTrainSeg = []\n",
    "\n",
    "for i in range(len(err_info)):\n",
    "    fileTrainSeg.append([' '.join(list(jieba.cut(err_info[i], cut_all=False)))]) #使用jieba进行分词\n",
    "\n",
    "print len(err_info), \"err-infos have been segmented.\"\n",
    "\n",
    "with open(fileSegWordDonePath,'wb') as fW:\n",
    "    for i in range(len(fileTrainSeg)):\n",
    "        fW.write(fileTrainSeg[i][0].encode('utf-8')) #将分词处理完成的文本写入TXT\n",
    "        fW.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2:载入停用词表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#从文件导入停用词表\n",
    "stpwrdpath = \"stop_words.txt\"\n",
    "stpwrd_dic = open(stpwrdpath, 'rb')\n",
    "stpwrd_content = stpwrd_dic.read()\n",
    "#将停用词表转换为list  \n",
    "stpwrdlst = stpwrd_content.splitlines()\n",
    "stpwrd_dic.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step ３：对分词后的数据进行向量化处理，这里我选用进行加权词频TF-IDF向量处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import sys\n",
    "\n",
    "reload(sys)\n",
    "sys.setdefaultencoding('utf-8') # 将系统默认编码格式设为UTF-8\n",
    "\n",
    "list_source = []\n",
    "\n",
    "for i in range(len(fileTrainSeg)):\n",
    "    column_list = fileTrainSeg[i][0].decode('utf-8')\n",
    "    list_source.append(column_list)  # 加入list_source\n",
    "\n",
    "#print list_source\n",
    "with open(\"list_source.txt\",'wb') as fW:\n",
    "    for i in range(len(list_source)):\n",
    "        fW.write(list_source[i].encode('utf-8'))\n",
    "        fW.write('\\n')\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words=stpwrdlst, min_df=1)\n",
    "\n",
    "list_tfidf = []\n",
    "\n",
    "list_tfidf = vectorizer.fit_transform(list_source) #计算各故障信息的TF-IDF，并将文本转换为词频矩阵\n",
    "\n",
    "print \"TF-IDF process finished.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "source": [
    "### step 4: 使用PCA对TF-IDF特征数据进行降维处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import SparsePCA\n",
    "\n",
    "#将TF-IDF词频矩阵的特征维度降低至适当值\n",
    "pca = SparsePCA(n_components=50)\n",
    "\n",
    "final_tfidf = pca.fit_transform(list_tfidf.toarray())\n",
    "\n",
    "print final_tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: 使用K-means对特征矩阵进行聚类处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "clf = KMeans(n_clusters=20)　　#设定K-means聚类为20个类簇\n",
    "\n",
    "s = clf.fit(final_tfidf)　　#训练聚类模型\n",
    "\n",
    "print s\n",
    "\n",
    "# 20个中心点\n",
    "print(clf.cluster_centers_)\n",
    "\n",
    "# 每个样本所属的簇\n",
    "print(clf.labels_)\n",
    "i = 1\n",
    "while i <= len(clf.labels_):\n",
    "    print i, clf.labels_[i - 1]\n",
    "    i = i + 1\n",
    "\n",
    "# 用来评估簇的个数是否合适，距离越小说明簇分的越好，选取临界点的簇个数\n",
    "print(clf.inertia_)\n",
    "\n",
    "for i in range(len(list_source)):\n",
    "\n",
    "    print list_source[i], clf.labels_[i]\n",
    "\n",
    "    \n",
    "j=0\n",
    "with open(\"result.txt\",'wb') as fW:　　#聚类结果存入文本文件中\n",
    "    while j <= 19:\n",
    "        fW.write('label')\n",
    "        fW.write(str(j).encode('utf-8'))\n",
    "        fW.write('\\n')\n",
    "        for i in range(len(list_source)):\n",
    "            if clf.labels_[i] == j:\n",
    "                fW.write(list_source[i].encode('utf-8'))\n",
    "                fW.write(str(clf.labels_[i]).encode('utf-8'))\n",
    "                fW.write('\\n')\n",
    "        j = j + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
